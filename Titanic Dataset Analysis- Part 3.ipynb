{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (KFold, train_test_split)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "stdsc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_data(filename):\n",
    "    titanic=pd.read_csv(filename,header=0,index_col=False)\n",
    "    \n",
    "    titanic=titanic.join(pd.get_dummies(titanic['Pclass'],drop_first=False))\n",
    "    titanic.rename(columns={1:'1st',2:'2nd',3:'3rd'},inplace=True)\n",
    "    \n",
    "    #Age_Known column with 1 value if age was originally known and 0 if unknown\n",
    "    age_known=titanic['Age'].isnull().tolist()\n",
    "    for index in range(0,len(age_known)):\n",
    "        if age_known[index]==False:\n",
    "            age_known[index]=0\n",
    "        else:\n",
    "            age_known[index]=1\n",
    "    titanic['Age_Known']=age_known\n",
    "    \n",
    "    #Fill Age column with Avg age as per Sex and PassengerClass\n",
    "    fem_avg_age_1=titanic['Age'][(titanic['Sex']=='female') & (titanic['Pclass']==1)].mean()\n",
    "    fem_avg_age_2=titanic['Age'][(titanic['Sex']=='female') & (titanic['Pclass']==2)].mean()\n",
    "    fem_avg_age_3=titanic['Age'][(titanic['Sex']=='female') & (titanic['Pclass']==3)].mean()\n",
    "    male_avg_age_3=titanic['Age'][(titanic['Sex']=='male') & (titanic['Pclass']==3)].mean()\n",
    "    male_avg_age_2=titanic['Age'][(titanic['Sex']=='male') & (titanic['Pclass']==2)].mean()\n",
    "    male_avg_age_1=titanic['Age'][(titanic['Sex']=='male') & (titanic['Pclass']==1)].mean()\n",
    "    for index in list(titanic.index):\n",
    "        if titanic.loc[index,'Sex']=='female' and titanic['Age'].isnull()[index]==True:\n",
    "            if titanic.loc[index,'Pclass']==1:\n",
    "                titanic.loc[index,'Age']=fem_avg_age_1\n",
    "            if titanic.loc[index,'Pclass']==2:\n",
    "                titanic.loc[index,'Age']=fem_avg_age_2\n",
    "            if titanic.loc[index,'Pclass']==3:\n",
    "                titanic.loc[index,'Age']=fem_avg_age_3\n",
    "        elif titanic.loc[index,'Sex']=='male' and titanic['Age'].isnull()[index]==True:\n",
    "            if titanic.loc[index,'Pclass']==3:\n",
    "                titanic.loc[index,'Age']=male_avg_age_3\n",
    "            if titanic.loc[index,'Pclass']==2:\n",
    "                titanic.loc[index,'Age']=male_avg_age_2\n",
    "            if titanic.loc[index,'Pclass']==1:\n",
    "                titanic.loc[index,'Age']=male_avg_age_1\n",
    "\n",
    "    #Create a column with 1 value if Passenger's cabin is known and 0 is unknown\n",
    "    cabin_known=[]\n",
    "    for index in list(titanic.index):\n",
    "        if titanic['Cabin'].isnull()[index]==True:\n",
    "            cabin_known.append(0)\n",
    "        else:\n",
    "            cabin_known.append(1)\n",
    "    titanic['cabin_known']=cabin_known\n",
    "    titanic.drop('Cabin',axis=1,inplace=True)\n",
    "    \n",
    "    #Split the Sex column into the specific columns for Males and Females\n",
    "    titanic=titanic.join(pd.get_dummies(titanic['Sex'],drop_first=True))\n",
    "\n",
    "    #Use the SiblingSpoouse and ParentsChildren columns to find the people with any immediate family on-board and those alone.\n",
    "    fam_on_board=[]\n",
    "    alone=[]\n",
    "    for index in list(titanic.index):\n",
    "        fam_on_board.append(titanic.loc[index,'SibSp']+titanic.loc[index,'Parch'])\n",
    "        if (titanic.loc[index,'SibSp']+titanic.loc[index,'Parch'])!=0:\n",
    "            alone.append(0)\n",
    "        else:\n",
    "            alone.append(1)\n",
    "    titanic['Fam_on_board']=fam_on_board\n",
    "    titanic['Alone']=alone\n",
    "\n",
    "    #Calculate the average cost per ticket for every individual to get a better idea of their wealth.\n",
    "    cost_per_ticketholder=[]\n",
    "    for index in list(titanic.index):\n",
    "        if titanic.loc[index,'Fam_on_board']==0:\n",
    "            cost_per_ticketholder.append(titanic.loc[index,'Fare'])\n",
    "        else:\n",
    "            cost_per_ticketholder.append(titanic.loc[index,'Fare']/titanic.loc[index,'Fam_on_board'])\n",
    "    titanic['Cost_per_ticketholder']=cost_per_ticketholder\n",
    "\n",
    "    #Get a separate column for each title in an individual's name to check for any correlation with their wealth and their chances of survival.\n",
    "    title=[]\n",
    "    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4}\n",
    "    for name in titanic['Name'].tolist():\n",
    "        short=name.split(',')[1].split('.')[0].replace(\" \",'')\n",
    "        try:\n",
    "            title.append(title_mapping[short])\n",
    "        except:\n",
    "            title.append(5)\n",
    "    titanic['Title']=title\n",
    "    \n",
    "    #Create the column 'Child' with entry as 1 if the age is less than 16 and as 0 if greater than 16 years. \n",
    "    Child=[]\n",
    "    for index in list(titanic.index):\n",
    "        if int(titanic.loc[index,'Age'])<16:\n",
    "            Child.append(1)\n",
    "        else:\n",
    "            Child.append(0)\n",
    "    titanic['Child']=Child\n",
    "    \n",
    "    #Split the embarked column into the specific columns for the 3 locations from where the passengers boarded the Titanic\n",
    "    titanic['Embarked'].fillna('S',axis=0,inplace=True)\n",
    "    titanic=titanic.join(pd.get_dummies(titanic['Embarked'],drop_first=False))\n",
    "    titanic.drop(['Embarked','Q'],axis=1,inplace=True)\n",
    "    \n",
    "    #Drop the extra columns\n",
    "    titanic.drop(['Pclass','Name','Sex','Ticket'],axis=1,inplace=True)\n",
    "    \n",
    "    return titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'Fare', '2nd', '3rd', 'male', 'Alone', 'Title', 'C',\n",
       "       'S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train=create_model_data('train.csv').drop(['PassengerId','Cost_per_ticketholder','Fam_on_board','1st','Child','SibSp','Parch', 'Age_Known','cabin_known'],axis=1)\n",
    "model_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test=create_model_data('test.csv')\n",
    "passenger_ID=model_test['PassengerId'].tolist()\n",
    "model_test.drop(['PassengerId','Cost_per_ticketholder','Fam_on_board','1st','Child','SibSp','Parch', 'Age_Known','cabin_known'],axis=1,inplace=True)\n",
    "model_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=model_train\n",
    "test=model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain=train.shape[0]\n",
    "ntest=test.shape[0]\n",
    "SEED=0\n",
    "NFOLDS=5\n",
    "kf=KFold(n_splits=NFOLDS,random_state=SEED)\n",
    "\n",
    "#create a class to extend the Sklearn Regressors\n",
    "class Sklearnhelper(object):\n",
    "    def __init__(self,clf,seed=0,params=None):\n",
    "        params['random_state']=seed\n",
    "        self.clf=clf(**params)\n",
    "    def train(self,x_train,y_train):\n",
    "        self.clf.train(x_train,y_train)\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FUNCTION TO GET THE OUT OF FOLD PREDICTIONS WHICH ARE USED AS NEW FEATURES TO THE SECOND LEVEL PREDICTION ##\n",
    "\n",
    "def get_oof(clf,x_train,y_train,x_test):\n",
    "    oof_train=np.zeros((ntrain,))\n",
    "    oof_test=np.zeros((ntest,))\n",
    "    oof_test_skf=np.empty((NFOLDS,ntest))\n",
    "    \n",
    "    for i,(train_index,test_index) in enumerate(kf.split(x_train)):\n",
    "        x_tr=x_train[train_index]\n",
    "        x_te=x_train[test_index]\n",
    "        y_tr=y_train[train_index]\n",
    "        \n",
    "        clf.fit(x_tr,y_tr)\n",
    "        \n",
    "        oof_train[test_index]=clf.predict(x_te)\n",
    "        oof_test_skf[i, :]=clf.predict(x_test)\n",
    "    oof_test[:]=oof_test_skf.mean(axis=0)\n",
    "    \n",
    "    return oof_train.reshape(-1,1), oof_test.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare the parameters that are used as input in the 5 regressors.\n",
    "rf_params={'n_jobs':-1,'n_estimators':500,'warm_start':True,'max_depth':6,'min_samples_leaf':2,'max_features':'sqrt','verbose':0}\n",
    "et_params={'n_jobs':-1,'n_estimators':500,'max_depth':6,'min_samples_leaf':2,'verbose':0}\n",
    "ada_params={'n_estimators':500,'learning_rate':0.75}\n",
    "gb_params={'n_estimators':500,'max_depth':5,'min_samples_leaf':2,'verbose':0}\n",
    "svc_params={'kernel':'linear','C':0.025}\n",
    "\n",
    "#Create the Regressor objects to represent our model\n",
    "rf=Sklearnhelper(clf=RandomForestClassifier,seed=SEED,params=rf_params)\n",
    "et=Sklearnhelper(clf=ExtraTreesClassifier,seed=SEED,params=et_params)\n",
    "gb=Sklearnhelper(clf=GradientBoostingClassifier,seed=SEED,params=gb_params)\n",
    "ada=Sklearnhelper(clf=AdaBoostClassifier,seed=SEED,params=ada_params)\n",
    "svc=Sklearnhelper(clf=SVC,seed=SEED,params=svc_params)\n",
    "\n",
    "#CREATE NUMPY ARRAYS TO BE USED AS INPUTS\n",
    "y_train=train['Survived'].ravel()\n",
    "x_train=train.drop('Survived',axis=1).values\n",
    "x_test=test.values\n",
    "\n",
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "rf_oof_train, rf_oof_test=get_oof(rf,x_train,y_train,x_test)\n",
    "et_oof_train, et_oof_test=get_oof(et,x_train,y_train,x_test)\n",
    "ada_oof_train, ada_oof_test=get_oof(ada,x_train,y_train,x_test)\n",
    "gb_oof_train, gb_oof_test=get_oof(gb,x_train,y_train,x_test)\n",
    "svc_oof_train, svc_oof_test=get_oof(svc,x_train,y_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11131913 0.19804143 0.02655306 0.11206939 0.2078013  0.02279361\n",
      " 0.28333042 0.02220792 0.01588374]\n",
      "[0.0321816  0.04769147 0.03279797 0.16096247 0.43943391 0.03213274\n",
      " 0.20346789 0.02502365 0.02630831]\n",
      "[0.16  0.724 0.014 0.034 0.014 0.008 0.03  0.004 0.012]\n",
      "[0.17308484 0.30640741 0.01151856 0.08157408 0.02208819 0.0069698\n",
      " 0.37886418 0.00477733 0.01471561]\n"
     ]
    }
   ],
   "source": [
    "rf_feature = rf.feature_importances(x_train,y_train)\n",
    "et_feature = et.feature_importances(x_train, y_train)\n",
    "ada_feature = ada.feature_importances(x_train, y_train)\n",
    "gb_feature = gb.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Copy-Paste the Feature Importances\n",
    "\n",
    "rf_features=[0.09293744, 0.0916828,  0.01569767, 0.02648281, 0.05161642, 0.19368762,\n",
    " 0.05686529, 0.01160524, 0.1740301,  0.28539461]\n",
    "et_features=[0.13174811, 0.02616867, 0.01129091, 0.02579529, 0.09254832, 0.43862129,\n",
    " 0.03836753, 0.02556649, 0.03009955, 0.17979385]\n",
    "ada_features=[0.01,  0.184, 0.024, 0.016, 0.014, 0.014, 0.052, 0.008, 0.64,  0.038]\n",
    "gb_features=[0.06535086, 0.15975638, 0.00579944, 0.01609369, 0.01991735, 0.01796385,\n",
    " 0.08568087, 0.00328791, 0.24858379, 0.37756586]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost feature importances</th>\n",
       "      <th>Extra Trees  feature importances</th>\n",
       "      <th>Gradient Boost feature importances</th>\n",
       "      <th>Random Forest feature importances</th>\n",
       "      <th>features</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.131748</td>\n",
       "      <td>0.065351</td>\n",
       "      <td>0.092937</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.075009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184</td>\n",
       "      <td>0.026169</td>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.091683</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.115402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>0.005799</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>Parch</td>\n",
       "      <td>0.014197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.025795</td>\n",
       "      <td>0.016094</td>\n",
       "      <td>0.026483</td>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.021093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.092548</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>cabin_known</td>\n",
       "      <td>0.044521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.438621</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.193688</td>\n",
       "      <td>male</td>\n",
       "      <td>0.166068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.038368</td>\n",
       "      <td>0.085681</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>Fam_on_board</td>\n",
       "      <td>0.058228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.011605</td>\n",
       "      <td>Alone</td>\n",
       "      <td>0.012115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.640</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.248584</td>\n",
       "      <td>0.174030</td>\n",
       "      <td>Cost_per_ticketholder</td>\n",
       "      <td>0.273178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.179794</td>\n",
       "      <td>0.377566</td>\n",
       "      <td>0.285395</td>\n",
       "      <td>Title</td>\n",
       "      <td>0.220189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AdaBoost feature importances  Extra Trees  feature importances  \\\n",
       "0                         0.010                          0.131748   \n",
       "1                         0.184                          0.026169   \n",
       "2                         0.024                          0.011291   \n",
       "3                         0.016                          0.025795   \n",
       "4                         0.014                          0.092548   \n",
       "5                         0.014                          0.438621   \n",
       "6                         0.052                          0.038368   \n",
       "7                         0.008                          0.025566   \n",
       "8                         0.640                          0.030100   \n",
       "9                         0.038                          0.179794   \n",
       "\n",
       "   Gradient Boost feature importances  Random Forest feature importances  \\\n",
       "0                            0.065351                           0.092937   \n",
       "1                            0.159756                           0.091683   \n",
       "2                            0.005799                           0.015698   \n",
       "3                            0.016094                           0.026483   \n",
       "4                            0.019917                           0.051616   \n",
       "5                            0.017964                           0.193688   \n",
       "6                            0.085681                           0.056865   \n",
       "7                            0.003288                           0.011605   \n",
       "8                            0.248584                           0.174030   \n",
       "9                            0.377566                           0.285395   \n",
       "\n",
       "                features      mean  \n",
       "0                 Pclass  0.075009  \n",
       "1                    Age  0.115402  \n",
       "2                  Parch  0.014197  \n",
       "3               Embarked  0.021093  \n",
       "4            cabin_known  0.044521  \n",
       "5                   male  0.166068  \n",
       "6           Fam_on_board  0.058228  \n",
       "7                  Alone  0.012115  \n",
       "8  Cost_per_ticketholder  0.273178  \n",
       "9                  Title  0.220189  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATE DATAFRAME OF THE FEATURE IMPORTANCES OF THE 4 MODELS\n",
    "\n",
    "feature_df=pd.DataFrame({'features':list(train.drop('Survived',axis=1).columns),'Random Forest feature importances': rf_features,\n",
    "     'Extra Trees  feature importances': et_features,\n",
    "      'AdaBoost feature importances': ada_features,\n",
    "    'Gradient Boost feature importances': gb_features})\n",
    "feature_df['mean']=feature_df.mean(axis=1)\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Second Level Predictions ##\n",
    "### USE OF THE FIRST LEVEL OUTPUTS AS NEW FEATURES AND USE IT FOR THE SECOND LEVEL PREDICTIONS USING XGB Classifier##\n",
    "\n",
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "     'AdaBoost': ada_oof_train.ravel(),\n",
    "      'GradientBoost': gb_oof_train.ravel()\n",
    "    })\n",
    "\n",
    "#Making the New Training & Testing Sets\n",
    "x_train=np.concatenate((et_oof_train,rf_oof_train,ada_oof_train,gb_oof_train,svc_oof_train),axis=1)\n",
    "x_test=np.concatenate((et_oof_test,rf_oof_test,ada_oof_test,gb_oof_test,svc_oof_test),axis=1)\n",
    "\n",
    "gbm = xgb.XGBClassifier(\n",
    "    #learning_rate = 0.02,\n",
    " n_estimators= 2000,\n",
    " max_depth= 4,\n",
    " min_child_weight= 2,\n",
    " #gamma=1,\n",
    " gamma=0.9,                        \n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread= -1,\n",
    " scale_pos_weight=1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create Submission file ##\n",
    "\n",
    "predictions=gbm.predict(x_test)\n",
    "Submission=pd.DataFrame({ 'PassengerId': passenger_ID,'Survived': predictions})\n",
    "Submission.to_csv(\"Submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
